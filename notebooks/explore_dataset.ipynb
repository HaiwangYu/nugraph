{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuGraph dataset quick look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook mirrors `scripts/explore_dataset.py` so you can inspect a few events and generate exploratory plots interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /exp/sbnd/app/users/yuhw/nugraph\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Change working directory\n",
    "os.chdir('/exp/sbnd/app/users/yuhw/nugraph')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\"axes.grid\": True,\n",
    "                     \"axes.spines.top\": False,\n",
    "                     \"axes.spines.right\": False,\n",
    "                     \"figure.dpi\": 120})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('test/NG2-paper.gnn.keep1.h5')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('test/NG2-paper.gnn.keep1.h5')\n",
    "split = 'test'\n",
    "limit = 3  # set to None to use every sample in the split\n",
    "outdir = Path('../plots_notebook')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bytes(values):\n",
    "    return [v.decode() if isinstance(v, (bytes, np.bytes_)) else str(v) for v in values]\n",
    "\n",
    "def load_sample(record):\n",
    "    return {field: record[field] for field in record.dtype.names}\n",
    "\n",
    "def semantic_palette(classes):\n",
    "    cmap = plt.colormaps.get_cmap('tab10', len(classes))\n",
    "    palette = {'background': '#b3b3b3'}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        palette[cls] = mcolors.to_hex(cmap(idx))\n",
    "    return palette\n",
    "\n",
    "def plot_semantic(sample_name, planes, semantic_labels, palette, record):\n",
    "    label_names = ['background'] + semantic_labels\n",
    "    nplanes = len(planes)\n",
    "    fig, axes = plt.subplots(1, nplanes, figsize=(4 * nplanes, 4), squeeze=False)\n",
    "    for ax, plane in zip(axes[0], planes):\n",
    "        pos = record[f'{plane}/pos']\n",
    "        y_sem = record[f'{plane}/y_semantic'].astype(int)\n",
    "        labels = [label_names[val + 1] for val in y_sem]\n",
    "        colours = [palette[label] for label in labels]\n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=colours, s=5, linewidths=0)\n",
    "        ax.set_title(f'{plane.upper()} plane')\n",
    "        ax.set_xlabel('proj')\n",
    "        ax.set_ylabel('drift')\n",
    "    fig.suptitle(f'Semantic truth – {sample_name}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{sample_name}_semantic.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_instances(sample_name, planes, record):\n",
    "    nplanes = len(planes)\n",
    "    fig, axes = plt.subplots(1, nplanes, figsize=(4 * nplanes, 4), squeeze=False)\n",
    "    for ax, plane in zip(axes[0], planes):\n",
    "        pos = record[f'{plane}/pos']\n",
    "        inst = record[f'{plane}/y_instance'].astype(int)\n",
    "        mask = inst >= 0\n",
    "        valid = np.unique(inst[mask])\n",
    "        if len(valid):\n",
    "            cmap = plt.colormaps.get_cmap('nipy_spectral', len(valid))\n",
    "            colours = [cmap(np.where(valid == val)[0][0]) if val in valid else '#b3b3b3' for val in inst]\n",
    "        else:\n",
    "            colours = ['#b3b3b3'] * len(inst)\n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=colours, s=5, linewidths=0)\n",
    "        vtx_key = f'{plane}/y_vtx'\n",
    "        if vtx_key in record and record[vtx_key].size:\n",
    "            vtx = record[vtx_key]\n",
    "            ax.scatter(vtx[:, 0], vtx[:, 1], marker='*', s=120, c='k')\n",
    "        ax.set_title(f'{plane.upper()} plane')\n",
    "        ax.set_xlabel('proj')\n",
    "        ax.set_ylabel('drift')\n",
    "    fig.suptitle(f'Instance ids – {sample_name}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{sample_name}_instances.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def update_counts(per_plane_counts, planes, semantic_labels, record):\n",
    "    for plane in planes:\n",
    "        y_sem = record[f'{plane}/y_semantic'].astype(int)\n",
    "        counts = np.bincount(y_sem + 1, minlength=len(semantic_labels) + 1)\n",
    "        per_plane_counts[plane] += counts\n",
    "\n",
    "def plot_semantic_summary(split_name, planes, semantic_labels, palette, per_plane_counts):\n",
    "    label_names = ['background'] + semantic_labels\n",
    "    indices = np.arange(len(planes))\n",
    "    bottom = np.zeros(len(planes), dtype=int)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    for label_idx, label in enumerate(label_names):\n",
    "        counts = np.array([per_plane_counts[p][label_idx] for p in planes])\n",
    "        ax.bar(indices, counts, 0.6, bottom=bottom, label=label, color=palette.get(label, '#999999'))\n",
    "        bottom += counts\n",
    "    ax.set_xticks(indices, [p.upper() for p in planes])\n",
    "    ax.set_ylabel('hit count')\n",
    "    ax.set_title(f'Semantic label distribution – {split_name}')\n",
    "    ax.legend(fontsize='small', loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{split_name}_semantic_summary.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ColormapRegistry.get_cmap() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m planes \u001b[38;5;241m=\u001b[39m decode_bytes(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplanes\u001b[39m\u001b[38;5;124m'\u001b[39m][()])\n\u001b[1;32m      3\u001b[0m semantic_labels \u001b[38;5;241m=\u001b[39m decode_bytes(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic_classes\u001b[39m\u001b[38;5;124m'\u001b[39m][()])\n\u001b[0;32m----> 4\u001b[0m palette \u001b[38;5;241m=\u001b[39m \u001b[43msemantic_palette\u001b[49m\u001b[43m(\u001b[49m\u001b[43msemantic_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m samples \u001b[38;5;241m=\u001b[39m decode_bytes(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m'\u001b[39m][split][()])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36msemantic_palette\u001b[0;34m(classes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msemantic_palette\u001b[39m(classes):\n\u001b[0;32m----> 8\u001b[0m     cmap \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolormaps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtab10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     palette \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackground\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#b3b3b3\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes):\n",
      "\u001b[0;31mTypeError\u001b[0m: ColormapRegistry.get_cmap() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path, 'r') as f:\n",
    "    planes = decode_bytes(f['planes'][()])\n",
    "    semantic_labels = decode_bytes(f['semantic_classes'][()])\n",
    "    palette = semantic_palette(semantic_labels)\n",
    "    samples = decode_bytes(f['samples'][split][()])\n",
    "    if limit is not None:\n",
    "        samples = samples[:limit]\n",
    "    per_plane_counts = {plane: np.zeros(len(semantic_labels) + 1, dtype=int) for plane in planes}\n",
    "    for sample in samples:\n",
    "        record = load_sample(f[f'dataset/{sample}'][()])\n",
    "        plot_semantic(sample, planes, semantic_labels, palette, record)\n",
    "        plot_instances(sample, planes, record)\n",
    "        update_counts(per_plane_counts, planes, semantic_labels, record)\n",
    "    plot_semantic_summary(split, planes, semantic_labels, palette, per_plane_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-clustering-eaf",
   "language": "python",
   "name": "dl-clustering-eaf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

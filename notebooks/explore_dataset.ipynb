{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuGraph dataset quick look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook mirrors `scripts/explore_dataset.py` so you can inspect a few events and generate exploratory plots interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\"axes.grid\": True,\n",
    "                     \"axes.spines.top\": False,\n",
    "                     \"axes.spines.right\": False,\n",
    "                     \"figure.dpi\": 120})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../test/NG2-paper.gnn.keep1.h5')\n",
    "split = 'test'\n",
    "limit = 3  # set to None to use every sample in the split\n",
    "outdir = Path('../plots_notebook')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bytes(values):\n",
    "    return [v.decode() if isinstance(v, (bytes, np.bytes_)) else str(v) for v in values]\n",
    "\n",
    "def load_sample(record):\n",
    "    return {field: record[field] for field in record.dtype.names}\n",
    "\n",
    "def semantic_palette(classes):\n",
    "    cmap = plt.colormaps.get_cmap('tab10', len(classes))\n",
    "    palette = {'background': '#b3b3b3'}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        palette[cls] = mcolors.to_hex(cmap(idx))\n",
    "    return palette\n",
    "\n",
    "def plot_semantic(sample_name, planes, semantic_labels, palette, record):\n",
    "    label_names = ['background'] + semantic_labels\n",
    "    nplanes = len(planes)\n",
    "    fig, axes = plt.subplots(1, nplanes, figsize=(4 * nplanes, 4), squeeze=False)\n",
    "    for ax, plane in zip(axes[0], planes):\n",
    "        pos = record[f'{plane}/pos']\n",
    "        y_sem = record[f'{plane}/y_semantic'].astype(int)\n",
    "        labels = [label_names[val + 1] for val in y_sem]\n",
    "        colours = [palette[label] for label in labels]\n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=colours, s=5, linewidths=0)\n",
    "        ax.set_title(f'{plane.upper()} plane')\n",
    "        ax.set_xlabel('proj')\n",
    "        ax.set_ylabel('drift')\n",
    "    fig.suptitle(f'Semantic truth – {sample_name}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{sample_name}_semantic.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_instances(sample_name, planes, record):\n",
    "    nplanes = len(planes)\n",
    "    fig, axes = plt.subplots(1, nplanes, figsize=(4 * nplanes, 4), squeeze=False)\n",
    "    for ax, plane in zip(axes[0], planes):\n",
    "        pos = record[f'{plane}/pos']\n",
    "        inst = record[f'{plane}/y_instance'].astype(int)\n",
    "        mask = inst >= 0\n",
    "        valid = np.unique(inst[mask])\n",
    "        if len(valid):\n",
    "            cmap = plt.colormaps.get_cmap('nipy_spectral', len(valid))\n",
    "            colours = [cmap(np.where(valid == val)[0][0]) if val in valid else '#b3b3b3' for val in inst]\n",
    "        else:\n",
    "            colours = ['#b3b3b3'] * len(inst)\n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=colours, s=5, linewidths=0)\n",
    "        vtx_key = f'{plane}/y_vtx'\n",
    "        if vtx_key in record and record[vtx_key].size:\n",
    "            vtx = record[vtx_key]\n",
    "            ax.scatter(vtx[:, 0], vtx[:, 1], marker='*', s=120, c='k')\n",
    "        ax.set_title(f'{plane.upper()} plane')\n",
    "        ax.set_xlabel('proj')\n",
    "        ax.set_ylabel('drift')\n",
    "    fig.suptitle(f'Instance ids – {sample_name}')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{sample_name}_instances.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def update_counts(per_plane_counts, planes, semantic_labels, record):\n",
    "    for plane in planes:\n",
    "        y_sem = record[f'{plane}/y_semantic'].astype(int)\n",
    "        counts = np.bincount(y_sem + 1, minlength=len(semantic_labels) + 1)\n",
    "        per_plane_counts[plane] += counts\n",
    "\n",
    "def plot_semantic_summary(split_name, planes, semantic_labels, palette, per_plane_counts):\n",
    "    label_names = ['background'] + semantic_labels\n",
    "    indices = np.arange(len(planes))\n",
    "    bottom = np.zeros(len(planes), dtype=int)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    for label_idx, label in enumerate(label_names):\n",
    "        counts = np.array([per_plane_counts[p][label_idx] for p in planes])\n",
    "        ax.bar(indices, counts, 0.6, bottom=bottom, label=label, color=palette.get(label, '#999999'))\n",
    "        bottom += counts\n",
    "    ax.set_xticks(indices, [p.upper() for p in planes])\n",
    "    ax.set_ylabel('hit count')\n",
    "    ax.set_title(f'Semantic label distribution – {split_name}')\n",
    "    ax.legend(fontsize='small', loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outdir / f'{split_name}_semantic_summary.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path, 'r') as f:\n",
    "    planes = decode_bytes(f['planes'][()])\n",
    "    semantic_labels = decode_bytes(f['semantic_classes'][()])\n",
    "    palette = semantic_palette(semantic_labels)\n",
    "    samples = decode_bytes(f['samples'][split][()])\n",
    "    if limit is not None:\n",
    "        samples = samples[:limit]\n",
    "    per_plane_counts = {plane: np.zeros(len(semantic_labels) + 1, dtype=int) for plane in planes}\n",
    "    for sample in samples:\n",
    "        record = load_sample(f[f'dataset/{sample}'][()])\n",
    "        plot_semantic(sample, planes, semantic_labels, palette, record)\n",
    "        plot_instances(sample, planes, record)\n",
    "        update_counts(per_plane_counts, planes, semantic_labels, record)\n",
    "    plot_semantic_summary(split, planes, semantic_labels, palette, per_plane_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-clustering-eaf",
   "language": "python",
   "name": "dl-clustering-eaf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
